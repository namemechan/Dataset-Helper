"""
íƒœê·¸ ì²˜ë¦¬ ëª¨ë“ˆ - íƒœê·¸ ì¹˜í™˜, ì‚­ì œ, ì´ë™ ë° ì •ë ¬ ê¸°ëŠ¥
"""
from pathlib import Path
from typing import List, Tuple, Dict, Set, Optional
from utils import PERSON_COUNT_TAGS, process_with_multicore
from functools import partial
import json
from datetime import datetime
import os

UNDO_DIR = Path("logs/undo")

class TagProcessor:
    @staticmethod
    def save_undo_info(folder_path: str, tag_history: List[Dict[str, str]]):
        """
        íƒœê·¸ ì²˜ë¦¬ ì‹¤í–‰ ì·¨ì†Œ ì •ë³´ ì €ì¥
        tag_history: [{"file": "relative_path", "content": "original content"}, ...] 
        """
        if not tag_history:
            return

        if not UNDO_DIR.exists():
            UNDO_DIR.mkdir(parents=True, exist_ok=True)
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        undo_filename = f"undo_tag_{timestamp}.json"
        undo_path = UNDO_DIR / undo_filename
        
        undo_data = {
            "type": "tag",
            "folder_path": str(Path(folder_path).absolute()),
            "timestamp": datetime.now().isoformat(),
            "history": tag_history
        }
        
        try:
            with open(undo_path, 'w', encoding='utf-8') as f:
                json.dump(undo_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"íƒœê·¸ ì‹¤í–‰ ì·¨ì†Œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    @staticmethod
    def undo_last_processing(folder_path: str) -> Tuple[int, int, List[str]]:
        """
        íƒœê·¸ ì²˜ë¦¬ ì‹¤í–‰ ì·¨ì†Œ
        """
        if not UNDO_DIR.exists():
            return 0, 0, ["ì‹¤í–‰ ì·¨ì†Œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."]
            
        # íƒœê·¸ undo íŒŒì¼ ê²€ìƒ‰
        files = sorted(UNDO_DIR.glob("undo_tag_*.json"), reverse=True)
        
        target_file = None
        current_path = Path(folder_path).absolute()
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if Path(data.get("folder_path", "")) == current_path:
                    target_file = file_path
                    break
            except:
                continue
        
        if not target_file:
            return 0, 0, ["ì‹¤í–‰ ì·¨ì†Œí•  íƒœê·¸ ì‘ì—… ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."]
            
        # ë³µêµ¬ ì‹œì‘
        success = 0
        fail = 0
        logs = []
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            history = data.get("history", [])
            folder = Path(folder_path)
            
            for item in history:
                rel_path = item['file']
                original_content = item['content']
                file_path = folder / rel_path
                
                try:
                    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                    # (ì‚­ì œëœ íƒœê·¸ë¥¼ ë³µêµ¬í•˜ëŠ” ê²ƒì´ë¯€ë¡œ ë‚´ìš©ë§Œ ëŒë ¤ë†“ìœ¼ë©´ ë¨)
                    # ë§Œì•½ íŒŒì¼ ìì²´ê°€ ì‚­ì œë˜ì—ˆë‹¤ë©´? (ë‹¨ì¼ íŒŒì¼ ì°¾ê¸° ë“±ì—ì„œ) -> ìƒì„±í•´ì¤Œ.
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                    success += 1
                    logs.append(f"ë³µêµ¬: {rel_path}")
                except Exception as e:
                    logs.append(f"ì—ëŸ¬ {rel_path}: {e}")
                    fail += 1
            
            # Undo íŒŒì¼ ì‚­ì œ
            target_file.unlink()
            logs.append(f"ì‹¤í–‰ ì·¨ì†Œ íŒŒì¼ ì‚­ì œë¨: {target_file.name}")
            
        except Exception as e:
            return 0, 0, [f"ì‹¤í–‰ ì·¨ì†Œ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}"]
            
        return success, fail, logs

    @staticmethod
    def parse_tags(tag_string: str) -> List[str]:
        """
        íƒœê·¸ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ê³  ê³µë°± ì œê±°, ë¹ˆ íƒœê·¸ ì œê±°
        """
        if not tag_string:
            return []
        tags = [tag.strip() for tag in tag_string.split(',')]
        return [tag for tag in tags if tag]
    
    @staticmethod
    def join_tags(tags: List[str]) -> str:
        """íƒœê·¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ê²°í•©"""
        return ', '.join(tags)

    @staticmethod
    def process_tags_logic(
        content: str, 
        options: Dict
    ) -> Tuple[str, List[str]]:
        """
        íƒœê·¸ ì²˜ë¦¬ í•µì‹¬ ë¡œì§
        """
        tags = TagProcessor.parse_tags(content)
        original_tags = tags[:]
        changes = []

        # 0. ëˆ„ë½ëœ ì¸ì›ìˆ˜ íƒœê·¸ ì¶”ê°€
        if options.get('use_missing_tag'):
            has_person_tag = any(tag in tags for tag in PERSON_COUNT_TAGS)
            if not has_person_tag:
                gender = options.get('missing_gender', 'girl')
                count = options.get('missing_count', '1')
                if count == "6+": new_tag = f"6+{gender}s"
                elif count == "1": new_tag = f"1{gender}"
                else: new_tag = f"{count}{gender}s"
                
                if new_tag not in tags:
                    tags.insert(0, new_tag)
                    changes.append(f"ì£¼ì…: ëˆ„ë½ëœ ì¸ì›ìˆ˜ íƒœê·¸ '{new_tag}' ì¶”ê°€")

        # --- í—¬í¼ í•¨ìˆ˜ ---
        def replace_subsequence(current_tags: List[str], find_seq: List[str], replace_seq: List[str] = None) -> Tuple[List[str], int]:
            if not find_seq: return current_tags, 0
            result_tags = []
            i = 0
            count = 0
            n = len(current_tags)
            m = len(find_seq)
            while i < n:
                if i + m <= n and current_tags[i:i+m] == find_seq:
                    if replace_seq: result_tags.extend(replace_seq)
                    count += 1
                    i += m
                else:
                    result_tags.append(current_tags[i])
                    i += 1
            return result_tags, count
            
        def check_condition(current_tags: List[str], condition_str: str) -> bool:
            if not condition_str: return False
            cond_tags = [t.strip() for t in condition_str.split('|') if t.strip()]
            for ct in cond_tags:
                if ct in current_tags: return True
            return False

        # 1. íƒœê·¸ ì¹˜í™˜
        if options.get('use_replace') and options.get('replace_find'):
            find_str = options['replace_find'].strip()
            replace_str = options.get('replace_with', '').strip()
            find_seq = TagProcessor.parse_tags(find_str)
            replace_seq = TagProcessor.parse_tags(replace_str)
            if find_seq:
                tags, replaced_count = replace_subsequence(tags, find_seq, replace_seq)
                if replaced_count > 0:
                    changes.append(f"ì¹˜í™˜: '{find_str}' â†’ '{replace_str}' ({replaced_count}ê±´)")

        # 1.5 ì¸ì ‘ íƒœê·¸ ìˆ˜ì • (New)
        if options.get('use_neighbor_modify') and options.get('neighbor_target'):
            target_tag = options['neighbor_target'].strip()
            neighbor_pos = options.get('neighbor_pos', 'after') # 'before' or 'after'
            add_pos = options.get('neighbor_add_pos', 'prefix') # 'prefix' or 'suffix'
            add_text = options.get('neighbor_text', '')
            
            if target_tag and add_text:
                new_tags = tags[:]
                modified_indices = set()
                
                # íƒ€ê²Ÿ íƒœê·¸ì˜ ëª¨ë“  ìœ„ì¹˜ ì°¾ê¸°
                for idx, tag in enumerate(tags):
                    if tag == target_tag:
                        # ì¸ì ‘ ì¸ë±ìŠ¤ ê³„ì‚°
                        n_idx = idx - 1 if neighbor_pos == 'before' else idx + 1
                        
                        if 0 <= n_idx < len(tags):
                            modified_indices.add(n_idx)
                
                # ì‹¤ì œ ìˆ˜ì • ì ìš© (ë’¤ì—ì„œë¶€í„° ìˆ˜ì •í•´ì•¼ ì¸ë±ìŠ¤ í˜¼ë€ ë°©ì§€ - ì—¬ê¸°ì„œëŠ” ì¸ë±ìŠ¤ ê³ ì •ì´ë¼ ìƒê´€ì—†ì§€ë§Œ ìŠµê´€ì  ì²˜ë¦¬)
                if modified_indices:
                    for m_idx in sorted(list(modified_indices), reverse=True):
                        orig_neighbor = tags[m_idx]
                        if add_pos == 'prefix':
                            tags[m_idx] = add_text + orig_neighbor
                        else:
                            tags[m_idx] = orig_neighbor + add_text
                    
                    changes.append(f"ì¸ì ‘ìˆ˜ì •: '{target_tag}'ì˜ {neighbor_pos} íƒœê·¸ì— '{add_text}' {add_pos} ì¶”ê°€")

        # 1.7 CSV ê¸°ë°˜ íŠ¹ìˆ˜ ì²˜ë¦¬ (New)
        if options.get('use_csv_process') and options.get('csv_tags_set'):
            csv_tags = options['csv_tags_set']
            csv_mode = options.get('csv_mode', 'add')
            csv_input = options.get('csv_input_text', '')
            csv_add_pos = options.get('csv_add_pos', 'prefix')
            
            new_tags_list = []
            csv_changes_count = 0
            
            for tag in tags:
                # ë¹„êµë¥¼ ìœ„í•œ ì •ê·œí™” (ì†Œë¬¸ìí™” ë° ì–¸ë”ë°”->ê³µë°±)
                normalized_tag = tag.lower().replace('_', ' ')
                
                if normalized_tag in csv_tags:
                    csv_changes_count += 1
                    if csv_mode == 'add':
                        processed_tag = (csv_input + tag) if csv_add_pos == 'prefix' else (tag + csv_input)
                        new_tags_list.append(processed_tag)
                    elif csv_mode == 'replace':
                        new_tags_list.append(csv_input)
                    elif csv_mode == 'delete':
                        continue # ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ì‚­ì œ)
                else:
                    new_tags_list.append(tag)
            
            if csv_changes_count > 0:
                tags = new_tags_list
                mode_name = "ì¶”ê°€" if csv_mode == 'add' else "ì¹˜í™˜" if csv_mode == 'replace' else "ì‚­ì œ"
                changes.append(f"CSVì²˜ë¦¬: {csv_changes_count}ê°œ íƒœê·¸ {mode_name} ì™„ë£Œ")

        # 2. íƒœê·¸ ì‚­ì œ
        if options.get('use_delete') and options.get('delete_tags'):
            should_delete = True
            if options.get('use_conditional_delete'):
                if not check_condition(tags, options.get('condition_delete_tags', '')):
                    should_delete = False
            
            if should_delete:
                raw_delete_input = options['delete_tags']
                total_deleted = 0
                deleted_items = []
                for del_item in raw_delete_input:
                    del_seq = TagProcessor.parse_tags(del_item)
                    if not del_seq: continue
                    tags, count = replace_subsequence(tags, del_seq, None)
                    if count > 0:
                        total_deleted += count
                        deleted_items.append(del_item)
                if total_deleted > 0:
                    changes.append(f"ì‚­ì œ: {', '.join(deleted_items)}")

        # 3. íƒœê·¸ ì´ë™ ë° ì •ë ¬
        use_person = options.get('use_move_person', False)
        use_solo = options.get('use_move_solo', False)
        use_custom = options.get('use_move_custom', False)
        
        person_group = []
        solo_group = []
        custom_group = []
        other_group = []
        custom_targets = set(options.get('move_custom_tags', [])) if use_custom else set()
        
        if use_person or use_solo or use_custom:
            for tag in tags:
                if use_person and tag in PERSON_COUNT_TAGS: person_group.append(tag)
                elif use_solo and tag == 'solo': solo_group.append(tag)
                elif use_custom and tag in custom_targets: custom_group.append(tag)
                else: other_group.append(tag)
            
            person_group.sort()
            front_tags = person_group + solo_group + custom_group
            
            # 4. íƒœê·¸ ì¶”ê°€ (ì´ë™ ì˜µì…˜ í™œì„±í™” ì‹œ)
            if options.get('use_add') and options.get('add_tags'):
                should_add = True
                if options.get('use_conditional_add'):
                    all_current_tags = person_group + solo_group + custom_group + other_group
                    if not check_condition(all_current_tags, options.get('condition_add_tags', '')):
                        should_add = False
                
                if should_add:
                    add_str = options['add_tags']
                    new_add_tags = TagProcessor.parse_tags(add_str)
                    if new_add_tags:
                        front_tags.extend(new_add_tags)
                        changes.append(f"ì¶”ê°€: '{add_str}'")

            new_order = front_tags + other_group
            if new_order != tags:
                tags = new_order
                moved_info = []
                if person_group: moved_info.append("ì¸ì›ìˆ˜")
                if solo_group: moved_info.append("solo")
                if custom_group: moved_info.append("ì§€ì • íƒœê·¸")
                if moved_info:
                    changes.append(f"ì´ë™: {', '.join(moved_info)} ì•ìœ¼ë¡œ")

        # 4. íƒœê·¸ ì¶”ê°€ (ì´ë™ ì˜µì…˜ ë¹„í™œì„±í™” ì‹œ)
        elif options.get('use_add') and options.get('add_tags'):
            should_add = True
            if options.get('use_conditional_add'):
                if not check_condition(tags, options.get('condition_add_tags', '')):
                    should_add = False
            
            if should_add:
                add_str = options['add_tags']
                new_add_tags = TagProcessor.parse_tags(add_str)
                if new_add_tags:
                    tags = new_add_tags + tags
                    changes.append(f"ì¶”ê°€: '{add_str}' (ë§¨ ì•)")

        final_content = TagProcessor.join_tags(tags)
        return final_content, changes

    @staticmethod
    def process_single_file(file_path: Path, options: Dict) -> Tuple[bool, str, List[str], str]:
        """
        ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ë˜í¼
        Returns: (is_changed, log_message, changes, original_content)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            new_content, changes = TagProcessor.process_tags_logic(content, options)
            
            if new_content != content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                return True, f"ë³€ê²½ë¨: {file_path.name} | {' / '.join(changes)}", changes, content
            else:
                return False, f"ë³€ê²½ ì—†ìŒ: {file_path.name}", [], content
        
        except Exception as e:
            return False, f"ì˜¤ë¥˜: {file_path.name} - {str(e)}", [], ""

    @staticmethod
    def process_folder(text_files: List[Path], options: Dict, num_cores: int = 1, folder_path: str = "") -> Tuple[int, int, List[str]]:
        """
        í´ë” ì¼ê´„ ì²˜ë¦¬
        folder_path: ìƒëŒ€ ê²½ë¡œ ê³„ì‚°ì„ ìœ„í•œ ê¸°ì¤€ í´ë” (Undo ì €ì¥ìš©)
        """
        if not text_files:
            return 0, 0, ["ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."]
        
        worker = partial(TagProcessor.process_single_file, options=options)
        
        results = process_with_multicore(
            worker,
            text_files,
            num_cores
        )
        
        success = 0
        fail = 0
        logs = []
        tag_history = []
        
        root_path = Path(folder_path).absolute() if folder_path else None
        
        for i, r in enumerate(results):
            is_changed, log_msg, changes, original_content = r
            logs.append(log_msg)
            
            if is_changed:
                success += 1
                if root_path:
                    try:
                        # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                        rel_path = str(text_files[i].absolute().relative_to(root_path))
                        tag_history.append({
                            "file": rel_path,
                            "content": original_content
                        })
                    except ValueError:
                        # ê²½ë¡œ ê³„ì‚° ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ íŒŒì¼ëª… ì‚¬ìš© (ìœ„í—˜í•˜ì§€ë§Œ ì°¨ì„ ì±…)
                        tag_history.append({
                            "file": text_files[i].name,
                            "content": original_content
                        })
            elif "ì˜¤ë¥˜" in log_msg:
                fail += 1
        
        if tag_history and folder_path:
            TagProcessor.save_undo_info(folder_path, tag_history)
        
        return success, fail, logs
    
    @staticmethod
    def preview_tag_processing(text_files: List[Path], options: Dict, preview_count: int = 10) -> List[str]:
        """
        ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        """
        if not text_files:
            return ["ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."]
        
        preview = []
        
        # ì˜µì…˜ ìš”ì•½
        op_summary = []
        if options.get('use_replace'): op_summary.append(f"[ì¹˜í™˜] {options['replace_find']} -> {options['replace_with']}")
        if options.get('use_delete'): 
            op_summary.append(f"[ì‚­ì œ] {len(options['delete_tags'])}ê°œ íƒœê·¸" + (" (ì¡°ê±´ë¶€)" if options.get('use_conditional_delete') else ""))
        if options.get('use_move_person'): op_summary.append("[ì´ë™] ì¸ì›ìˆ˜ íƒœê·¸")
        if options.get('use_move_custom'): op_summary.append(f"[ì´ë™] ì‚¬ìš©ì ì§€ì • {len(options['move_custom_tags'])}ê°œ íƒœê·¸")
        if options.get('use_add'):
            op_summary.append(f"[ì¶”ê°€] {options['add_tags']}" + (" (ì¡°ê±´ë¶€)" if options.get('use_conditional_add') else ""))

        preview.append(f"ì ìš© ì˜µì…˜: {', '.join(op_summary) if op_summary else 'ì—†ìŒ'}\n")
        preview.append("-" * 50)
        
        count = 0
        processed_count = 0
        
        for file_path in text_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                
                new_content, changes = TagProcessor.process_tags_logic(content, options)
                
                if changes: # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°
                    processed_count += 1
                    if count < preview_count:
                        preview.append(f"ğŸ“„ {file_path.name}")
                        for change in changes:
                            preview.append(f"  â”” {change}")
                        
                        short_orig = (content[:60] + '...') if len(content) > 60 else content
                        short_new = (new_content[:60] + '...') if len(new_content) > 60 else new_content
                        
                        preview.append(f"  [ì „] {short_orig}")
                        preview.append(f"  [í›„] {short_new}")
                        preview.append("")
                        count += 1
            except Exception as e:
                if count < preview_count:
                    preview.append(f"âŒ {file_path.name}: {e}")
                    count += 1
        
        # ë§¨ ì•ì— ìš”ì•½ ì¶”ê°€ (ìˆœì„œìƒ ë¦¬ìŠ¤íŠ¸ insert ì‚¬ìš©)
        summary_lines = [
            f"ê²€ìƒ‰ëœ ì „ì²´ íŒŒì¼: {len(text_files)}ê°œ",
            f"ë³€ê²½ ëŒ€ìƒ íŒŒì¼: {processed_count}ê°œ",
            ""
        ]
        
        # ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        final_preview = summary_lines + preview
        
        if count == 0 and processed_count == 0:
            final_preview.append("ì„¤ì •ëœ ì˜µì…˜ìœ¼ë¡œ ë³€ê²½ë˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        elif count < processed_count:
             final_preview.append(f"... ì™¸ {processed_count - count}ê°œ íŒŒì¼ ë³€ê²½ ì˜ˆì •")
            
        return final_preview